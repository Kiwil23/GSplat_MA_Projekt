# GSplat_MA_Projekt

## Pipeline auf dem Cluster ausfÃ¼hren

### ğŸ“¦ Enroot-Container klonen

1. Frontend Ã¶ffnen:  
   ğŸ‘‰ [https://ood-1.ai.lrz.de/pun/sys/dashboard](https://ood-1.ai.lrz.de/pun/sys/dashboard)

2. Einen Ordner `Containers` im `/home`-Verzeichnis anlegen.

3. Mit SSH verbinden:
   ```bash
   ssh login.ai.lrz.de -l xxyyyzz
   cd Containers
   ```

4. Interaktive Session starten:
   ```bash
   salloc -p lrz-hgx-h100-94x4 --gres=gpu:1
   ```

5. PrÃ¼fen, ob H100 GPU zugewiesen ist:
   ```bash
   srun nvidia-smi
   ```

6. Docker-Image mit Enroot importieren (**nur auf Compute-Knoten**):
   ```bash
   srun enroot import docker://kiwil23/splat_tools_slim
   ```

7. Session mit `exit` beenden.

8. Datei umbenennen:
   ```bash
   Von kiwil23+splat_tools_slim.sqsh in kiwil23_splat_tools_slim.sqsh
   ```

---

### ğŸ§± Pipeline-Umgebung vorbereiten

**Verzeichnisstruktur erstellen:**

```
Jobs/
â”œâ”€â”€ gpu_job.sbatch

Containers/
â”œâ”€â”€ input_data/
â”œâ”€â”€ result_data/
â””â”€â”€ scripts/
```

- In `Containers/scripts/` (Cluster) alle Dateien aus (Repo) `pipeline_assets/main_pipeline/scripts` kopieren  
- `gpu_job.sbatch` in `Jobs/` speichern und darin die Pfade entsprechend auf die `Containers/`-Struktur anpassen

---

### â–¶ï¸ Pipeline ausfÃ¼hren

In `gpu_job.sbatch` kÃ¶nnen folgende Argumente gesetzt werden:

#### FÃ¼r .mp4 in `input_data/`:

| Argument                    | Beschreibung                                                  |
|----------------------------|---------------------------------------------------------------|
| `--pipeline_type="mp4_to_images"`            | extrahiert Einzelframes                                       |
| `--pipeline_type="mp4_to_colmap"`            | gibt COLMAP-Ergebnisse zurÃ¼ck                                |
| `--pipeline_type="mp4_to_transforms"`        | COLMAP â†’ fÃ¼r Splatfacto vorbereitet                          |
| `--pipeline_type="mp4_to_splat"`             | (Default) vollstÃ¤ndige Pipeline inkl. .ply fÃ¼r Training                |

#### FÃ¼r Einzelbilder in `input_data/`:

| Argument                    | Beschreibung                                                  |
|----------------------------|---------------------------------------------------------------|
| `--pipeline_type="images_to_colmap"`         | gibt COLMAP-Ergebnisse zurÃ¼ck                                |
| `--pipeline_type="images_to_transforms"`     | COLMAP â†’ fÃ¼r Splatfacto vorbereitet                          |
| `--pipeline_type="images_to_splat"`          | vollstÃ¤ndige Pipeline inkl. .ply fÃ¼r Training                |

#### FÃ¼r vorhandene COLMAP-Daten in ` input_data` :

Ordnerstruktur:
```
input_data/
â”œâ”€â”€ images/
â”œâ”€â”€ sparse/
â””â”€â”€ database.db
```

| Argument                    | Beschreibung                                                  |
|----------------------------|---------------------------------------------------------------|
| `--pipeline_type="colmap_to_transforms"`     | fÃ¼r Splatfacto vorbereiten                                   |
| `--pipeline_type="colmap_to_splat"`          | vollstÃ¤ndige Pipeline inkl. .ply fÃ¼r Training                |

#### FÃ¼r vorbereitete COLMAP-Daten fÃ¼r Splatfacto ` input_data` :

Ordnerstruktur:
```
input_data/
â”œâ”€â”€ colmap/
â”‚   â”œâ”€â”€ sparse/
â”‚   â””â”€â”€ database.db
â”œâ”€â”€ images/
â”œâ”€â”€ images_2/
â”œâ”€â”€ images_4/
â”œâ”€â”€ images_8/
â”œâ”€â”€ sparse_pc/
â””â”€â”€ transforms.json
```

| Argument                    | Beschreibung                                                  |
|----------------------------|---------------------------------------------------------------|
| `--pipeline_type="transforms_to_splat"`      | vollstÃ¤ndige Pipeline inkl. .ply fÃ¼r Training                |

#### ZusÃ¤tzliche Filterung:

| Option             | Wirkung                                                                   |
|--------------------|---------------------------------------------------------------------------|
| `--pre_filter_img`  |Filterung vor raft_extractor Bilderauswahl z.B. --pre_filter_img="30" Behalte 30% der schÃ¤rften Bilder (zusÃ¤tzlich feste 5 % extra Filterung von unbrauchbaren Bildern  |
| `--post_filter_img` |Filterung nach raft_extractor Bilderauswahl z.B. --pre_filter_img="60" Behalte 60% der schÃ¤rften Bilder  |
|`--train_img_percentage`|Vie viele Bilder fÃ¼r das Splat Training genutzt werden z.B. --train_img_percentage="90" Trainiere den Splat mit 90% der verbleibenden Bilder |
#### Pipeline starten:

```bash
sbatch gpu_job.sbatch
```

---

### ğŸ› ï¸ Fehlerbehebung

Fehlermeldung:
```
sbatch: error: Batch script contains DOS line breaks (\r\n)
sbatch: error: instead of expected UNIX line breaks (\n).
```

Beheben mit:
```bash
sed -i 's/\r$//' gpu_job.sbatch
sbatch gpu_job.sbatch
```
```
Sicherstellen das die Pointcloud in sparse/0 liegt
Sollte Sie z.B. in sparse/1 liegen, alle anderen Pointcloud Ordner lÃ¶schen
und in Pipeline.py fÃ¼r den gewÃ¼nschten Schritt bei prepare_colmap_data_for_splatfacto()
os.path.join(input_data_dir, "sparse/0")) ---> os.path.join(input_data_dir, "sparse/1"))
```
---

### ğŸ§© scripts-Verzeichnis

- EnthÃ¤lt `pipeline.py` â†’ steuert den Ablauf im Container  
- Kann modifiziert werden, um die Pipeline anzupassen  
- Output liegt in `result_data/` als `splat.ply`, Trainingsdaten, und Rohdaten von Splatfacto

---

## ğŸ’» Lokale AusfÃ¼hrung

### Vorbereitung:

1. **Windows:** Docker Desktop installieren  
   ğŸ‘‰ [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)  
   - WSL2 aktivieren  
   - ggf. `.wslconfig` anpassen

2. **Linux:**  
   ğŸ‘‰ [https://docs.docker.com/engine/install/ubuntu/](https://docs.docker.com/engine/install/ubuntu/)

3. **NVIDIA Container Toolkit installieren:**  
   ğŸ‘‰ [https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)

4. **Verzeichnisstruktur anlegen:**
```
MeinVerzeichnis/
â”œâ”€â”€ input_data/
â”œâ”€â”€ result_data/
â””â”€â”€ scripts/
```

5. Docker-Image bauen:
```bash
cd <FULL_PATH_TO>/Docker
docker build -t <IMAGE_NAME> .
```

6. Container starten:
```bash
docker run -it --gpus all \
  -v <FULL_PATH_TO>/input_data:/mnt/input_data \
  -v <FULL_PATH_TO>/result_data:/mnt/result_data \
  -v <FULL_PATH_TO>/scripts:/mnt/pipeline_scripts \
  -p 7007:7007 <IMAGE_NAME> \
  python3 /mnt/pipeline_scripts/pipeline.py \
  --pipeline_type="mp4_to_splat" \
  --is_big_dataset="False" && echo "pipeline.py done"
```
oder mit Mockup.sh unter `pipeline_assets/jobscripts/Mockup.sh` 

7. Output liegt in `result_data/`

---

## ğŸ“¦ DockerHub Image

ğŸ”— [https://hub.docker.com/repository/docker/kiwil23/splat_tools_slim/general](https://hub.docker.com/repository/docker/kiwil23/splat_tools_slim/general)
